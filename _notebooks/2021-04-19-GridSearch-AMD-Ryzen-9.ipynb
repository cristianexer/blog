{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search on AMD Ryzen 9 5950X 16-Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Claims Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "![](https://images.propertycasualty360.com/contrib/content/uploads/sites/414/2018/05/Telemactics_Feature_Car.jpg)\n",
    "\n",
    "**[Dataset](https://www.kaggle.com/xiaomengsun/car-insurance-claim-data)**\n",
    "\n",
    "|VARIABLE NAME|DEFINITION                              |THEORETICAL EFFECT                                                                               |\n",
    "|-------------|----------------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "|INDEX        |Identification Variable (do not use)    |None                                                                                             |\n",
    "|TARGET FLAG  |Was Car in a crash? 1=YES 0=NO          |None                                                                                             |\n",
    "|TARGET AMT   |If car was in a crash, what was the cost|None                                                                                             |\n",
    "|AGE          |Age of Driver                           |Very young people tend to be risky. Maybe very old people also.                                  |\n",
    "|BLUEBOOK     |Value of Vehicle                        |Unknown effect on probability of collision, but probably effect the payout if there is a crash   |\n",
    "|CAR AGE      |Vehicle Age                             |Unknown effect on probability of collision, but probably effect the payout if there is a crash   |\n",
    "|CAR TYPE     |Type of Car                             |Unknown effect on probability of collision, but probably effect the payout if there is a crash   |\n",
    "|CAR USE      |Vehicle Use                             |Commercial vehicles are driven more, so might increase probability of collision                  |\n",
    "|CLM FREQ     |# Claims (Past 5 Years)                 |The more claims you filed in the past, the more you are likely to file in the future             |\n",
    "|EDUCATION    |Max Education Level                     |Unknown effect, but in theory more educated people tend to drive more safely                     |\n",
    "|HOMEKIDS     |# Children at Home                      |Unknown effect                                                                                   |\n",
    "|HOME VAL     |Home Value                              |In theory, home owners tend to drive more responsibly                                            |\n",
    "|INCOME       |Income                                  |In theory, rich people tend to get into fewer crashes                                            |\n",
    "|JOB          |Job Category                            |In theory, white collar jobs tend to be safer                                                    |\n",
    "|KIDSDRIV     |# Driving Children                      |When teenagers drive your car, you are more likely to get into crashes                           |\n",
    "|MSTATUS      |Marital Status                          |In theory, married people drive more safely                                                      |\n",
    "|MVR PTS      |Motor Vehicle Record Points             |If you get lots of traffic tickets, you tend to get into more crashes                            |\n",
    "|OLDCLAIM     |Total Claims (Past 5 Years)             |If your total payout over the past five years was high, this suggests future payouts will be high|\n",
    "|PARENT1      |Single Parent                           |Unknown effect                                                                                   |\n",
    "|RED CAR      |A Red Car                               |Urban legend says that red cars (especially red sports cars) are more risky. Is that true?       |\n",
    "|REVOKED      |License Revoked (Past 7 Years)          |If your license was revoked in the past 7 years, you probably are a more risky driver.           |\n",
    "|SEX          |Gender                                  |Urban legend says that women have less crashes then men. Is that true?                           |\n",
    "|TIF          |Time in Force                           |People who have been customers for a long time are usually more safe.                            |\n",
    "|TRAVTIME     |Distance to Work                        |Long drives to work usually suggest greater risk                                                 |\n",
    "|URBANICITY   |Home/Work Area                          |Unknown                                                                                          |\n",
    "|YOJ          |Years on Job                            |People who stay at a job for a long time are usually more safe                                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>homekids</th>\n",
       "      <th>mstatus</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>car_use</th>\n",
       "      <th>bluebook</th>\n",
       "      <th>tif</th>\n",
       "      <th>car_type</th>\n",
       "      <th>red_car</th>\n",
       "      <th>oldclaim</th>\n",
       "      <th>clm_freq</th>\n",
       "      <th>clm_amt</th>\n",
       "      <th>claim_flag</th>\n",
       "      <th>urbanicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Private</td>\n",
       "      <td>14230.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>1</td>\n",
       "      <td>4461.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>High School</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>14940.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Private</td>\n",
       "      <td>21970.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Van</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  homekids  mstatus gender    education     car_use  bluebook  tif  \\\n",
       "0  60.0         0        0      M          PhD     Private   14230.0   11   \n",
       "1  43.0         0        0      M  High School  Commercial   14940.0    1   \n",
       "2  48.0         0        0      M    Bachelors     Private   21970.0    1   \n",
       "\n",
       "  car_type  red_car  oldclaim  clm_freq  clm_amt  claim_flag urbanicity  \n",
       "0  Minivan        1    4461.0         2      0.0           0      Urban  \n",
       "1  Minivan        1       0.0         0      0.0           0      Urban  \n",
       "2      Van        1       0.0         0      0.0           0      Urban  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('data/car_insurance_claim.csv')\n",
    "\n",
    "# make columns lowercase\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# drop useless columns\n",
    "df = df.drop(['kidsdriv','parent1','revoked','mvr_pts','travtime','id','birth'],axis=1)\n",
    "\n",
    "# clean money amounts\n",
    "df[['home_val','bluebook','oldclaim','clm_amt','income']] = df[['home_val','bluebook','oldclaim','clm_amt','income']].apply(lambda x: x.str.replace('$','',regex=False).str.replace(',','',regex=False)).astype(float)\n",
    "\n",
    "# clean values from columns\n",
    "to_clean = ['education','occupation','mstatus','gender','car_type']\n",
    "for col in to_clean:\n",
    "    df[col] = df[col].str.replace('z_','',regex=False).str.replace('<','',regex=False)\n",
    "\n",
    "df['urbanicity'] = df['urbanicity'].str.split('/ ',expand=True)[1]\n",
    "\n",
    "to_clean = ['mstatus','red_car']\n",
    "for col in to_clean:\n",
    "    df[col] = df[col].str.lower().replace({ 'yes': True, 'no': False}).astype(int)\n",
    "    \n",
    "df = df.drop(['car_age','occupation','home_val','income','yoj'],axis=1).dropna()\n",
    "  \n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = df.copy()\n",
    "processed_df[['gender','education','car_use','car_type','urbanicity']] = processed_df[['gender','education','car_use','car_type','urbanicity']].apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(processed_df, test_size=0.33, random_state=42, stratify=processed_df['claim_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age','homekids','mstatus','gender','education','car_use','bluebook','tif','car_type','red_car','clm_amt','urbanicity']\n",
    "target = 'clm_amt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Tweedie Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=32, num_parallel_tree=1,\n",
       "             objective='reg:tweedie', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=None, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective='reg:tweedie')\n",
    "model.fit(train[features],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcris\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 24.143000250200103\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', metrics.mean_squared_error(test[target], test_preds, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.05, 0.1],\n",
       " 'max_depth': [1, 3, 5, 7, 9, 11],\n",
       " 'min_child_weight': [3, 5, 7],\n",
       " 'gamma': [0.1, 0.3],\n",
       " 'colsample_bytree': [0.3, 0.5, 0.7],\n",
       " 'n_estimators': [50, 65, 80, 95, 110],\n",
       " 'objective': ['reg:tweedie'],\n",
       " 'tweedie_variance_power': [1.5],\n",
       " 'eval_metric': ['tweedie-nloglik@1.5']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate'    : [0.05, 0.10 ],\n",
    "    'max_depth'        : list(range(1,13,2)),\n",
    "    'min_child_weight' : [ 3, 5, 7 ],\n",
    "    'gamma'            : [ 0.1, 0.3],\n",
    "    'colsample_bytree' : [ 0.3, 0.5 , 0.7 ],\n",
    "    'n_estimators' : list(range(50,120,15)),\n",
    "    'objective': ['reg:tweedie'],\n",
    "    'tweedie_variance_power': [1.5],\n",
    "    'eval_metric': ['tweedie-nloglik@1.5']\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = xgb.XGBRegressor()\n",
    "grid = GridSearchCV(\n",
    "    estimator=grid_model,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1080 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=...\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.7],\n",
       "                         'eval_metric': ['tweedie-nloglik@1.5'],\n",
       "                         'gamma': [0.1, 0.3], 'learning_rate': [0.05, 0.1],\n",
       "                         'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                         'min_child_weight': [3, 5, 7],\n",
       "                         'n_estimators': [50, 65, 80, 95, 110],\n",
       "                         'objective': ['reg:tweedie'],\n",
       "                         'tweedie_variance_power': [1.5]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(train[features],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'eval_metric': 'tweedie-nloglik@1.5',\n",
       " 'gamma': 0.3,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 7,\n",
       " 'n_estimators': 110,\n",
       " 'objective': 'reg:tweedie',\n",
       " 'tweedie_variance_power': 1.5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcris\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_estimator_preds = grid.best_estimator_.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 232.32622429061522\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', metrics.mean_squared_error(test[target], best_estimator_preds, squared=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
